{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as pyo\n",
    "\n",
    "\n",
    "from src.download import download_experiment_data, download_recprice_data, download_order_data, download_tender_data\n",
    "from src.metrics import calculate_absolute_metrics, get_switchback_results, calculate_ratio_metrics\n",
    "from src.prepare import prepare_recprice_data, prepare_order_data, get_orders_with_recprice_df, get_hex\n",
    "from src.visualization import plot_switches_matrix, plot_conversions_by_time, plot_prices_by_time\n",
    "from src.visualization import plot_metric_by_time, plot_metric_by_hex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SB Results: Bad Bids\n",
    "\n",
    "- link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Костыли"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def load_data(DATA_ROOT_PATH, file_prefix):\n",
    "    \"\"\"\n",
    "    Загружает данные из CSV или Parquet файла\n",
    "    \n",
    "    Args:\n",
    "        DATA_ROOT_PATH: путь к директории с данными\n",
    "        file_prefix: префикс файла ('df_recprice', 'df_tenders' или 'df_orders')\n",
    "    \"\"\"\n",
    "    csv_path = DATA_ROOT_PATH / f'{file_prefix}.csv'\n",
    "    pqt_path = DATA_ROOT_PATH / f'{file_prefix}.pqt'\n",
    "    \n",
    "    # Проверяем наличие файлов\n",
    "    csv_exists = csv_path.exists()\n",
    "    pqt_exists = pqt_path.exists()\n",
    "    \n",
    "    if not csv_exists and not pqt_exists:\n",
    "        raise FileNotFoundError(f\"Не найдено ни одного файла для {file_prefix}! \"\n",
    "                              f\"Проверьте наличие файлов:\\n\"\n",
    "                              f\"{csv_path}\\n{pqt_path}\")\n",
    "    \n",
    "    # Определяем колонки с датами в зависимости от типа файла\n",
    "    if file_prefix == 'df_recprice':\n",
    "        date_columns = ['utc_recprice_dttm', 'local_recprice_dttm']\n",
    "    else:\n",
    "        date_columns = ['utc_order_dttm', 'local_order_dttm']\n",
    "    \n",
    "    # Если есть только один файл\n",
    "    if csv_exists and not pqt_exists:\n",
    "        print(f\"Найден только CSV файл для {file_prefix}\")\n",
    "        df = pd.read_csv(csv_path)\n",
    "        # Преобразуем все даты в datetime\n",
    "        for col in date_columns:\n",
    "            if col in df.columns and not pd.api.types.is_datetime64_any_dtype(df[col]):\n",
    "                df[col] = pd.to_datetime(df[col])\n",
    "        print(f\"\\nCSV файл {file_prefix}:\")\n",
    "        print(f\"Строк: {len(df)}\")\n",
    "        print(f\"Даты: с {df[date_columns[0]].min()} по {df[date_columns[0]].max()}\")\n",
    "        return df\n",
    "    \n",
    "    if pqt_exists and not csv_exists:\n",
    "        print(f\"Найден только Parquet файл для {file_prefix}\")\n",
    "        df = pd.read_parquet(pqt_path)\n",
    "        # Преобразуем все даты в datetime\n",
    "        for col in date_columns:\n",
    "            if col in df.columns and not pd.api.types.is_datetime64_any_dtype(df[col]):\n",
    "                df[col] = pd.to_datetime(df[col])\n",
    "        print(f\"\\nParquet файл {file_prefix}:\")\n",
    "        print(f\"Строк: {len(df)}\")\n",
    "        print(f\"Даты: с {df[date_columns[0]].min()} по {df[date_columns[0]].max()}\")\n",
    "        return df\n",
    "    \n",
    "    # Если есть оба файла - оригинальная логика\n",
    "    print(f\"Найдены оба файла для {file_prefix}, сравниваем даты...\")\n",
    "    \n",
    "    # Загружаем оба файла\n",
    "    df_csv = pd.read_csv(csv_path)\n",
    "    df_pqt = pd.read_parquet(pqt_path)\n",
    "    \n",
    "    # Преобразуем все даты в datetime для обоих датафреймов\n",
    "    for col in date_columns:\n",
    "        if col in df_csv.columns and not pd.api.types.is_datetime64_any_dtype(df_csv[col]):\n",
    "            df_csv[col] = pd.to_datetime(df_csv[col])\n",
    "        if col in df_pqt.columns and not pd.api.types.is_datetime64_any_dtype(df_pqt[col]):\n",
    "            df_pqt[col] = pd.to_datetime(df_pqt[col])\n",
    "    \n",
    "    # Приводим даты к единому формату (без временной зоны)\n",
    "    for col in date_columns:\n",
    "        if col in df_csv.columns and df_csv[col].dt.tz is not None:\n",
    "            df_csv[col] = df_csv[col].dt.tz_localize(None)\n",
    "        if col in df_pqt.columns and df_pqt[col].dt.tz is not None:\n",
    "            df_pqt[col] = df_pqt[col].dt.tz_localize(None)\n",
    "    \n",
    "    # Получаем максимальные даты\n",
    "    max_date_csv = df_csv[date_columns[0]].max()\n",
    "    max_date_pqt = df_pqt[date_columns[0]].max()\n",
    "    \n",
    "    print(f\"\\nCSV файл {file_prefix}:\")\n",
    "    print(f\"Строк: {len(df_csv)}\")\n",
    "    print(f\"Даты: с {df_csv[date_columns[0]].min()} по {max_date_csv}\")\n",
    "    \n",
    "    print(f\"\\nParquet файл {file_prefix}:\")\n",
    "    print(f\"Строк: {len(df_pqt)}\")\n",
    "    print(f\"Даты: с {df_pqt[date_columns[0]].min()} по {max_date_pqt}\")\n",
    "    \n",
    "    # Находим пересечение дат\n",
    "    csv_dates = set(df_csv[date_columns[0]].dt.date)\n",
    "    pqt_dates = set(df_pqt[date_columns[0]].dt.date)\n",
    "    common_dates = csv_dates.intersection(pqt_dates)\n",
    "    \n",
    "    # Подсчитываем количество строк в период пересечения\n",
    "    csv_common_rows = df_csv[df_csv[date_columns[0]].dt.date.isin(common_dates)].shape[0]\n",
    "    pqt_common_rows = df_pqt[df_pqt[date_columns[0]].dt.date.isin(common_dates)].shape[0]\n",
    "    \n",
    "    print(f\"\\nПериод пересечения дат:\")\n",
    "    print(f\"Количество дней: {len(common_dates)}\")\n",
    "    print(f\"Количество строк в CSV: {csv_common_rows}\")\n",
    "    print(f\"Количество строк в Parquet: {pqt_common_rows}\")\n",
    "    \n",
    "    # Выбираем файл с более поздней датой\n",
    "    if max_date_csv > max_date_pqt:\n",
    "        print(\"\\nВыбран CSV файл (более поздняя дата)\")\n",
    "        return df_csv\n",
    "    else:\n",
    "        print(\"\\nВыбран Parquet файл (более поздняя дата)\")\n",
    "        return df_pqt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Mutable__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_ID = 2763\n",
    "USER_NAME = 'nusuev_sb'+str(EXP_ID)\n",
    "\n",
    "ORDER_TYPE = 'auto_econom'\n",
    "ORDER_TYPE_ID = 1\n",
    "\n",
    "DAYS_BEFORE = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Immutable__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT_PATH = pathlib.Path(f'data/exp_id={EXP_ID}')\n",
    "if not DATA_ROOT_PATH.exists():\n",
    "    DATA_ROOT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "\n",
    "PLOT_ROOT_PATH = pathlib.Path(f'data/exp_id={EXP_ID}/plots')\n",
    "if not PLOT_ROOT_PATH.exists():\n",
    "    PLOT_ROOT_PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Download__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    before_start_date: 2025-02-28\n",
      "    exp_start_date: 2025-02-28\n",
      "    exp_stop_date: 2025-03-28\n",
      "    city_id: 4515\n",
      "    exp_name: (re-) [4515, Puerto Vallarta] Bad Bids v0\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "df_exp = download_experiment_data(exp_id=EXP_ID, user_name=USER_NAME)\n",
    "\n",
    "df_exp['hour'] = df_exp['switch_start_dttm'].dt.hour\n",
    "df_exp['hour'] = df_exp['hour'].astype('category')\n",
    "df_exp['weekday_name'] = df_exp['switch_start_dttm'].dt.day_name()\n",
    "df_exp['weekday_name'] = df_exp['weekday_name'].astype('category')\n",
    "\n",
    "df_exp.to_parquet(DATA_ROOT_PATH / 'df_exp.pqt')\n",
    "\n",
    "EXP_START_DATE = df_exp.utc_start_dttm.dt.date.astype('str').iloc[0]\n",
    "EXP_STOP_DATE = df_exp.utc_finish_dttm.dt.date.astype('str').iloc[0]\n",
    "BEFORE_START_DATE = (df_exp.utc_start_dttm.dt.date - timedelta(days=DAYS_BEFORE)).astype('str').iloc[0]\n",
    "CITY_ID = df_exp.city_id.iloc[0]\n",
    "EXP_NAME = df_exp.exp_name.iloc[0]\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "    before_start_date: {BEFORE_START_DATE}\n",
    "    exp_start_date: {EXP_START_DATE}\n",
    "    exp_stop_date: {EXP_STOP_DATE}\n",
    "    city_id: {CITY_ID}\n",
    "    exp_name: {EXP_NAME}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Validity__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Switch Splitting. Total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp.groupby('group_name').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Switch Splitting. By week day and hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_switches_matrix(df_exp, plot_root_path, is_show=True):\n",
    "    \n",
    "    pyo.init_notebook_mode()\n",
    "    \n",
    "    gb = (df_exp\n",
    "          .groupby(['weekday_name', 'hour', 'group_name'])\n",
    "          .size()\n",
    "          .rename('switches_count')\n",
    "          .reset_index()\n",
    "          .pivot(index=['weekday_name', 'hour'], columns='group_name', values='switches_count')\n",
    "          .reset_index())\n",
    "    gb['abs_diff'] = gb['A'] - gb['Control']\n",
    "    gb = gb.pivot(index='hour', columns='weekday_name', values='abs_diff')\n",
    "    gb = gb[['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']]\n",
    "    \n",
    "    fig = px.imshow(gb, labels=dict(x=\"Day of Week\", y=\"Hour of Day\", color='A - Control'))\n",
    "    fig.write_html(plot_root_path / 'switches_matrix.html')\n",
    "    \n",
    "    if is_show:\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_switches_matrix(\n",
    "    df_exp,\n",
    "    plot_root_path=PLOT_ROOT_PATH,\n",
    "    is_show=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Recprice__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recprice = download_recprice_data(\n",
    "    start_date=BEFORE_START_DATE,\n",
    "    stop_date=EXP_STOP_DATE,\n",
    "    city_id=CITY_ID,\n",
    "    user_name=USER_NAME,\n",
    "    printBool=True\n",
    ")\n",
    "df_recprice.to_parquet(DATA_ROOT_PATH / 'df_recprice.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recprice = load_data(DATA_ROOT_PATH, 'df_recprice')\n",
    "df_recprice_prepared = prepare_recprice_data(df_recprice)\n",
    "df_recprice_prepared.to_parquet(DATA_ROOT_PATH / 'df_recprice_prepared.pqt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Tenders__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    WITH incity AS (SELECT *\n",
      "                    FROM (SELECT city_id                                                                  AS city_id,\n",
      "                                order_type                                                                AS order_type,\n",
      "                                order_uuid                                                                AS order_uuid,\n",
      "                                user_id                                                                   AS user_id,\n",
      "                                order_timestamp                                                           AS local_order_dttm,\n",
      "                                TIMESTAMP(FORMAT_TIMESTAMP('%Y-%m-%d %H:%M:%S', order_timestamp),\n",
      "                                        timezone)                                                         AS utc_order_dttm,\n",
      "                                tender_uuid                                                               AS tender_uuid,\n",
      "                                driver_id                                                                 AS driver_id,\n",
      "                                price_highrate_usd                                                        AS price_highrate_usd,\n",
      "                                price_start_usd                                                           AS price_start_usd,\n",
      "                                price_order_usd                                                           AS price_order_usd,\n",
      "                                price_tender_usd                                                          AS price_tender_usd,\n",
      "                                driveraccept_timestamp IS NOT NULL                                        AS is_order_accepted,\n",
      "                                driverdone_timestamp IS NOT NULL                                          AS is_order_done,\n",
      "                                tender_uuid IS NOT NULL                                                   AS is_order_with_tender,\n",
      "                                price_start_usd = price_tender_usd                                        AS is_order_start_price_bid,\n",
      "                                fromlatitude                                                              AS fromlatitude,\n",
      "                                fromlongitude                                                             AS fromlongitude,\n",
      "                                duration_in_seconds / 60                                                  AS duration_in_min,\n",
      "                                distance_in_meters / 1000                                                 AS distance_in_km,\n",
      "                        FROM `indriver-e6e40.emart.incity_detail`\n",
      "                        WHERE true\n",
      "                            AND created_date_order_part >= DATE_SUB(DATE('2025-02-28'), INTERVAL 1 DAY)\n",
      "                            AND created_date_order_part <= DATE_ADD(DATE('2025-03-28'), INTERVAL 1 DAY)\n",
      "                            AND city_id = 4515)\n",
      "                    WHERE DATE(utc_order_dttm) BETWEEN DATE('2025-02-28') AND DATE('2025-03-28')),\n",
      "\n",
      "        bid_data AS (SELECT DISTINCT uuid                                                     AS tender_uuid,\n",
      "                                    order_uuid                                               AS order_uuid,\n",
      "                                    price                                                    AS bid_price,\n",
      "                                    modified_at                                              AS modified_at_utc,\n",
      "                                    SAFE_CAST(SUBSTR(eta, 1, STRPOS(eta, 's') - 1) AS INT64) AS eta,\n",
      "                                    available_prices                                         AS available_prices,\n",
      "                                    COALESCE(\n",
      "                                            (SELECT CASE\n",
      "                                                     -- WHEN price = last_pass_price\n",
      "                                                     --     THEN 'startprice'\n",
      "                                                        WHEN price = available_prices[offset]\n",
      "                                                            THEN 'option ' || CAST(offset + 1 AS STRING)\n",
      "                                                        WHEN price < available_prices[SAFE_OFFSET(0)]\n",
      "                                                     --     THEN 'option 1-'\n",
      "                                                            THEN 'startprice'\n",
      "                                                        WHEN price >\n",
      "                                                            available_prices[SAFE_OFFSET(ARRAY_LENGTH(available_prices) - 1)]\n",
      "                                                            THEN 'option ' || CAST(ARRAY_LENGTH(available_prices) AS STRING) || '+'\n",
      "                                                        ELSE 'option ' || CAST(offset + 1 AS STRING) ||\n",
      "                                                            (CASE WHEN price > available_prices[offset] THEN '+' ELSE '-' END)\n",
      "                                                        END\n",
      "                                            FROM UNNEST(available_prices) WITH OFFSET AS offset\n",
      "                                            WHERE price = available_prices[offset]\n",
      "                                                OR (price < available_prices[offset] AND\n",
      "                                                    (offset = 0 OR price > available_prices[offset - 1]))\n",
      "                                                OR (price > available_prices[offset] AND\n",
      "                                                    (offset = ARRAY_LENGTH(available_prices) - 1 OR\n",
      "                                                    price < available_prices[offset + 1]))\n",
      "                                            LIMIT 1),\n",
      "                                            'other'\n",
      "                                    )                                                        AS option_number\n",
      "                    FROM `indriver-e6e40.ods_new_order_rh_cdc.bid_global_strm`\n",
      "                    WHERE true\n",
      "                        AND order_uuid IS NOT NULL\n",
      "                        AND uuid IS NOT NULL\n",
      "                        AND order_uuid IN (SELECT order_uuid FROM incity)\n",
      "                        AND status = 'BID_STATUS_ACTIVE'\n",
      "                        AND DATE(created_at) BETWEEN\n",
      "                        DATE_SUB('2025-02-28', INTERVAL 1 DAY)\n",
      "                        AND DATE_ADD('2025-03-28', INTERVAL 1 DAY)),\n",
      "\n",
      "        tenders_tbl AS (SELECT incity.*,\n",
      "                               bid_data.bid_price / coalesce(multiplier_data.multiplier, 100) AS bid_price_currency,\n",
      "                               ARRAY(SELECT price / coalesce(multiplier_data.multiplier, 100) FROM UNNEST(bid_data.available_prices) as price) AS available_prices_currency,\n",
      "                               bid_data.eta,\n",
      "                               bid_data.option_number\n",
      "                        FROM incity\n",
      "                                LEFT JOIN bid_data\n",
      "                                        ON incity.order_uuid = bid_data.order_uuid\n",
      "                                            AND incity.tender_uuid = bid_data.tender_uuid\n",
      "                                LEFT JOIN (SELECT city_id,\n",
      "                                                  MAX(multiplier) AS multiplier\n",
      "                                            FROM `indriver-e6e40.ods_new_order_rh_cdc.order_global_strm`\n",
      "                                            WHERE true\n",
      "                                                AND city_id IN (SELECT DISTINCT city_id FROM incity)\n",
      "                                                AND DATE(created_at) >= DATE_SUB(DATE('2025-02-28'), INTERVAL 1 DAY)\n",
      "                                                AND DATE(created_at) <= DATE_ADD(DATE('2025-03-28'), INTERVAL 1 DAY)\n",
      "                                            GROUP BY city_id) AS multiplier_data\n",
      "                                        ON incity.city_id = multiplier_data.city_id\n",
      "                        WHERE true)\n",
      "\n",
      "    SELECT \n",
      "        *,\n",
      "        switch_start_dttm, \n",
      "        switch_finish_dttm,\n",
      "        hex_from,\n",
      "        IF(\n",
      "            mmhash IS NULL, \n",
      "            IF(group_name IS NULL, 'Before', group_name),\n",
      "            IF(MOD(mmhash, 100) < 50, 'A','Control')\n",
      "        ) AS tender_group_name\n",
      "    FROM (\n",
      "        SELECT  *,\n",
      "                CAST(\n",
      "                    IF(\n",
      "                     is_hex,\n",
      "                     `indriver-e6e40.de_functions.murmurhash32`(exp_salt || switch_start_dttm_unix || hex_from),\n",
      "                      NULL\n",
      "                    ) AS INTEGER\n",
      "                ) AS mmhash\n",
      "        FROM (\n",
      "            SELECT \n",
      "                t1.*, \n",
      "                t2.* EXCEPT(city_id),\n",
      "                `indriver-e6e40.de_functions.h3_lat_lng_to_cell_temp`(\n",
      "                    t1.fromlatitude, \n",
      "                    t1.fromlongitude, \n",
      "                    IF(t2.hexagon_size IS NULL, 7, t2.hexagon_size)\n",
      "                ) AS hex_from\n",
      "            FROM tenders_tbl t1\n",
      "            LEFT JOIN `analytics-dev-333113.temp.nusuev_sb2763_exp` t2\n",
      "                ON  t1.city_id = t2.city_id\n",
      "                AND t1.utc_order_dttm >= t2.switch_start_dttm\n",
      "                AND t1.utc_order_dttm < t2.switch_finish_dttm\n",
      "        ) \n",
      "    )\n",
      "    \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_tenders \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_tender_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBEFORE_START_DATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstop_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEXP_STOP_DATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcity_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCITY_ID\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mUSER_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprintBool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m df_tenders\u001b[38;5;241m.\u001b[39mto_parquet(DATA_ROOT_PATH \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_tenders.pqt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/PycharmProjects/work/badbids/exp_anal/SB/results/src/download.py:554\u001b[0m, in \u001b[0;36mdownload_tender_data\u001b[0;34m(start_date, stop_date, city_id, user_name, printBool)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m printBool:\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;28mprint\u001b[39m(query)\n\u001b[0;32m--> 554\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py:2057\u001b[0m, in \u001b[0;36mQueryJob.to_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, max_results, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[1;32m   1827\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_dataframe\u001b[39m(\n\u001b[1;32m   1828\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1829\u001b[0m     bqstorage_client: Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbigquery_storage.BigQueryReadClient\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1849\u001b[0m     ] \u001b[38;5;241m=\u001b[39m DefaultPandasDTypes\u001b[38;5;241m.\u001b[39mRANGE_TIMESTAMP_DTYPE,\n\u001b[1;32m   1850\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas.DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1851\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a pandas DataFrame from a QueryJob\u001b[39;00m\n\u001b[1;32m   1852\u001b[0m \n\u001b[1;32m   1853\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2055\u001b[0m \u001b[38;5;124;03m            :mod:`shapely` library cannot be imported.\u001b[39;00m\n\u001b[1;32m   2056\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2057\u001b[0m     query_result \u001b[38;5;241m=\u001b[39m \u001b[43mwait_for_query\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_bar_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2058\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m query_result\u001b[38;5;241m.\u001b[39mto_dataframe(\n\u001b[1;32m   2059\u001b[0m         bqstorage_client\u001b[38;5;241m=\u001b[39mbqstorage_client,\n\u001b[1;32m   2060\u001b[0m         dtypes\u001b[38;5;241m=\u001b[39mdtypes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2074\u001b[0m         range_timestamp_dtype\u001b[38;5;241m=\u001b[39mrange_timestamp_dtype,\n\u001b[1;32m   2075\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/google/cloud/bigquery/_tqdm_helpers.py:107\u001b[0m, in \u001b[0;36mwait_for_query\u001b[0;34m(query_job, progress_bar_type, max_results)\u001b[0m\n\u001b[1;32m    103\u001b[0m progress_bar \u001b[38;5;241m=\u001b[39m get_progress_bar(\n\u001b[1;32m    104\u001b[0m     progress_bar_type, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery is running\u001b[39m\u001b[38;5;124m\"\u001b[39m, default_total, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m )\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m progress_bar \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mquery_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py:1681\u001b[0m, in \u001b[0;36mQueryJob.result\u001b[0;34m(self, page_size, max_results, retry, timeout, start_index, job_retry)\u001b[0m\n\u001b[1;32m   1676\u001b[0m     remaining_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1679\u001b[0m     \u001b[38;5;66;03m# Since is_job_done() calls jobs.getQueryResults, which is a\u001b[39;00m\n\u001b[1;32m   1680\u001b[0m     \u001b[38;5;66;03m# long-running API, don't delay the next request at all.\u001b[39;00m\n\u001b[0;32m-> 1681\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mis_job_done\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1682\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1683\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1684\u001b[0m     \u001b[38;5;66;03m# Use a monotonic clock since we don't actually care about\u001b[39;00m\n\u001b[1;32m   1685\u001b[0m     \u001b[38;5;66;03m# daylight savings or similar, just the elapsed time.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py:1650\u001b[0m, in \u001b[0;36mQueryJob.result.<locals>.is_job_done\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1646\u001b[0m \u001b[38;5;66;03m# Call jobs.getQueryResults with max results set to 0 just to\u001b[39;00m\n\u001b[1;32m   1647\u001b[0m \u001b[38;5;66;03m# wait for the query to finish. Unlike most methods,\u001b[39;00m\n\u001b[1;32m   1648\u001b[0m \u001b[38;5;66;03m# jobs.getQueryResults hangs as long as it can to ensure we\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m \u001b[38;5;66;03m# know when the query has finished as soon as possible.\u001b[39;00m\n\u001b[0;32m-> 1650\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reload_query_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mreload_query_results_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;66;03m# Even if the query is finished now according to\u001b[39;00m\n\u001b[1;32m   1653\u001b[0m \u001b[38;5;66;03m# jobs.getQueryResults, we'll want to reload the job status if\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m \u001b[38;5;66;03m# it's not already DONE.\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py:1448\u001b[0m, in \u001b[0;36mQueryJob._reload_query_results\u001b[0;34m(self, retry, timeout, page_size)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transport_timeout, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m)):\n\u001b[1;32m   1446\u001b[0m         transport_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_query_results\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1449\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1450\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransport_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpage_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpage_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1456\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/google/cloud/bigquery/client.py:2034\u001b[0m, in \u001b[0;36mClient._get_query_results\u001b[0;34m(self, job_id, retry, project, timeout_ms, location, timeout, page_size)\u001b[0m\n\u001b[1;32m   2030\u001b[0m \u001b[38;5;66;03m# This call is typically made in a polling loop that checks whether the\u001b[39;00m\n\u001b[1;32m   2031\u001b[0m \u001b[38;5;66;03m# job is complete (from QueryJob.done(), called ultimately from\u001b[39;00m\n\u001b[1;32m   2032\u001b[0m \u001b[38;5;66;03m# QueryJob.result()). So we don't need to poll here.\u001b[39;00m\n\u001b[1;32m   2033\u001b[0m span_attributes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m: path}\n\u001b[0;32m-> 2034\u001b[0m resource \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2035\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2036\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspan_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBigQuery.getQueryResults\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2037\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspan_attributes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspan_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2038\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2039\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2041\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2042\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _QueryResults\u001b[38;5;241m.\u001b[39mfrom_api_repr(resource)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/google/cloud/bigquery/client.py:843\u001b[0m, in \u001b[0;36mClient._call_api\u001b[0;34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m create_span(\n\u001b[1;32m    841\u001b[0m         name\u001b[38;5;241m=\u001b[39mspan_name, attributes\u001b[38;5;241m=\u001b[39mspan_attributes, client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, job_ref\u001b[38;5;241m=\u001b[39mjob_ref\n\u001b[1;32m    842\u001b[0m     ):\n\u001b[0;32m--> 843\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call()\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/google/cloud/_http/__init__.py:482\u001b[0m, in \u001b[0;36mJSONConnection.api_request\u001b[0;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout, extra_api_info)\u001b[0m\n\u001b[1;32m    479\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(data)\n\u001b[1;32m    480\u001b[0m     content_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 482\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontent_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_target_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_api_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_api_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_http_response(response)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/google/cloud/_http/__init__.py:341\u001b[0m, in \u001b[0;36mJSONConnection._make_request\u001b[0;34m(self, method, url, data, content_type, headers, target_object, timeout, extra_api_info)\u001b[0m\n\u001b[1;32m    338\u001b[0m     headers[CLIENT_INFO_HEADER] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_agent\n\u001b[1;32m    339\u001b[0m headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_agent\n\u001b[0;32m--> 341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_object\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/google/cloud/_http/__init__.py:379\u001b[0m, in \u001b[0;36mJSONConnection._do_request\u001b[0;34m(self, method, url, headers, data, target_object, timeout)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_request\u001b[39m(\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28mself\u001b[39m, method, url, headers, data, target_object, timeout\u001b[38;5;241m=\u001b[39m_DEFAULT_TIMEOUT\n\u001b[1;32m    347\u001b[0m ):  \u001b[38;5;66;03m# pylint: disable=unused-argument\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Low-level helper:  perform the actual API request over HTTP.\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \n\u001b[1;32m    350\u001b[0m \u001b[38;5;124;03m    Allows batch context managers to override and defer a request.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;124;03m    :returns: The HTTP response.\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/google/auth/transport/requests.py:537\u001b[0m, in \u001b[0;36mAuthorizedSession.request\u001b[0;34m(self, method, url, data, headers, max_allowed_time, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    534\u001b[0m remaining_time \u001b[38;5;241m=\u001b[39m guard\u001b[38;5;241m.\u001b[39mremaining_timeout\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m TimeoutGuard(remaining_time) \u001b[38;5;28;01mas\u001b[39;00m guard:\n\u001b[0;32m--> 537\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mAuthorizedSession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    545\u001b[0m remaining_time \u001b[38;5;241m=\u001b[39m guard\u001b[38;5;241m.\u001b[39mremaining_timeout\n\u001b[1;32m    547\u001b[0m \u001b[38;5;66;03m# If the response indicated that the credentials needed to be\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;66;03m# refreshed, then refresh the credentials and re-attempt the\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;66;03m# request.\u001b[39;00m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;66;03m# A stored token may expire between the time it is retrieved and\u001b[39;00m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;66;03m# the time the request is made, so we may need to try twice.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/urllib3/connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/http/client.py:1348\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1349\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1350\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/http/client.py:316\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/http/client.py:277\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 277\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/ssl.py:1132\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_tenders = download_tender_data(\n",
    "    start_date=BEFORE_START_DATE,\n",
    "    stop_date=EXP_STOP_DATE,\n",
    "    city_id=CITY_ID,\n",
    "    user_name=USER_NAME,\n",
    "    printBool=True\n",
    ")\n",
    "df_tenders.to_parquet(DATA_ROOT_PATH / 'df_tenders.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tenders = load_data(DATA_ROOT_PATH, 'df_tenders')\n",
    "df_tenders_prepared = prepare_order_data(df_tenders)\n",
    "df_tenders_prepared.to_parquet(DATA_ROOT_PATH / 'df_tenders_prepared.pqt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Orders (with recprice)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders = download_order_data(\n",
    "    start_date=BEFORE_START_DATE,\n",
    "    stop_date=EXP_STOP_DATE,\n",
    "    city_id=CITY_ID,\n",
    "    user_name=USER_NAME,\n",
    "    printBool=True\n",
    ")\n",
    "df_orders.to_parquet(DATA_ROOT_PATH / 'df_orders.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders = load_data(DATA_ROOT_PATH, 'df_orders')\n",
    "df_orders_prepared = prepare_order_data(df_orders)\n",
    "df_orders_prepared.to_parquet(DATA_ROOT_PATH / 'df_orders_prepared.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders_with_recprice = get_orders_with_recprice_df(df_orders_prepared, df_recprice_prepared)\n",
    "df_orders_with_recprice['group_name'] = df_orders_with_recprice['recprice_group_name']\n",
    "df_orders_with_recprice.to_parquet(DATA_ROOT_PATH / 'df_orders_with_recprice.pqt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXP_ID = 2574\n",
    "# DATA_ROOT_PATH = pathlib.Path(f'data/exp_id={EXP_ID}')\n",
    "\n",
    "# df_recprice_prepared = pd.read_parquet(DATA_ROOT_PATH / 'df_recprice_prepared.pqt')\n",
    "# df_orders_with_recprice = pd.read_parquet(DATA_ROOT_PATH / 'df_orders_with_recprice.pqt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Total__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_total = calculate_absolute_metrics(\n",
    "    df_recprice_prepared,\n",
    "    df_orders_with_recprice,\n",
    "    group_cols=['group_name', 'switch_start_dttm', 'switch_finish_dttm'],\n",
    ")\n",
    "\n",
    "metrics_total_tbl = get_switchback_results(df_metrics_total, alpha=0.05)[\n",
    "    ['metric', 'control_value', 'experimental_value', 'uplift_rel', 'pvalue', 'is_significant']\n",
    "]\n",
    "\n",
    "metrics_total_tbl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__By segment__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_on_recprice = df_recprice_prepared.order_type_id == ORDER_TYPE_ID\n",
    "condition_on_orders = df_orders_with_recprice.order_type == ORDER_TYPE\n",
    "\n",
    "df_metrics_total = calculate_absolute_metrics(\n",
    "    df_recprice_prepared[condition_on_recprice].copy(),\n",
    "    df_orders_with_recprice[condition_on_orders].copy(),\n",
    "    group_cols=['group_name', 'switch_start_dttm', 'switch_finish_dttm'],\n",
    ")\n",
    "\n",
    "metrics_total_tbl = get_switchback_results(df_metrics_total, alpha=0.05)[\n",
    "    ['metric', 'control_value', 'experimental_value', 'uplift_rel', 'pvalue', 'is_significant']\n",
    "]\n",
    "\n",
    "metrics_total_tbl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP_COLS = ['group_name', 'time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Absolute Metrics\n",
    "df_metrics_grouped = calculate_absolute_metrics(\n",
    "    df_recprice_prepared,\n",
    "    df_orders_with_recprice,\n",
    "    group_cols=GROUP_COLS,\n",
    ")\n",
    "\n",
    "# Calculate Ratio Metrics\n",
    "df_metrics_grouped = calculate_ratio_metrics(df_metrics_grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Conversions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_conversions_by_time(\n",
    "    df_metrics_grouped,\n",
    "    grouped_column='time',\n",
    "    plot_root_path=PLOT_ROOT_PATH,\n",
    "    is_before=True,\n",
    "    is_show=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prices_by_time(\n",
    "    df_metrics_grouped,\n",
    "    grouped_column='time',\n",
    "    plot_root_path=PLOT_ROOT_PATH,\n",
    "    is_before=True,\n",
    "    is_show=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_by_time(\n",
    "    df_metrics_grouped,\n",
    "    grouped_column='time',\n",
    "    metric_name='surge',\n",
    "    plot_root_path=PLOT_ROOT_PATH,\n",
    "    is_before=True,\n",
    "    is_show=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(\n",
    "    df_recprice_prepared,\n",
    "    x='surge',\n",
    "    hue='group_name',\n",
    "    hue_order=['Control', 'A'],\n",
    "    bins=np.arange(0.85, 2.85, 0.02),\n",
    ").set_title('Total');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "client = bigquery.Client(project='analytics-dev-333113')\n",
    "\n",
    "query = f\"\"\"\n",
    "DECLARE start_date DATE;\n",
    "SET start_date = DATE '2024-01-01';\n",
    "\n",
    "select DATE_SUB(start_date, INTERVAL 1 DAY);\n",
    "    \"\"\"\n",
    "    \n",
    "client.query(query).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# side note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders_with_recprice = pd.read_parquet('data/exp_id=2640/df_orders_with_recprice.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders_with_recprice = df_orders_with_recprice[df_orders_with_recprice.order_type == ORDER_TYPE]\n",
    "df_orders_with_recprice.head().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recprice_prepared = pd.read_parquet('data/exp_id=2640/df_recprice_prepared.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recprice_prepared = df_recprice_prepared[df_recprice_prepared.order_type_id == ORDER_TYPE_ID]\n",
    "df_recprice_prepared.head().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.metrics as metrics\n",
    "\n",
    "def calculate_absolute_metrics(df_recprice, df_order_with_recprice, group_cols):\n",
    "    dfm = (metrics.metric_accepted_orders_count(df_order_with_recprice, group_cols)\n",
    "           .merge(metrics.metric_bids_count(df_order_with_recprice, group_cols), on=group_cols, how='left'))\n",
    "    return dfm\n",
    "\n",
    "\n",
    "df_metrics_total = calculate_absolute_metrics(\n",
    "    df_recprice_prepared,\n",
    "    df_orders_with_recprice,\n",
    "    group_cols=['order_uuid', 'group_name'],\n",
    ")\n",
    "\n",
    "df_metrics_total['acceptance_rate'] = df_metrics_total['accepted_orders_count'] / df_metrics_total['bids_count']\n",
    "\n",
    "df_metrics_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "df_metrics_total = calculate_absolute_metrics(\n",
    "    df_recprice_prepared,\n",
    "    df_orders_with_recprice,\n",
    "    group_cols=['order_uuid', 'group_name'],\n",
    ")\n",
    "\n",
    "df_metrics_total['acceptance_rate'] = df_metrics_total['accepted_orders_count'] / df_metrics_total['bids_count']\n",
    "df_metrics_total = df_metrics_total[df_metrics_total['bids_count'] > 0]\n",
    "\n",
    "sns.histplot(\n",
    "    df_metrics_total,\n",
    "    x='acceptance_rate',\n",
    "    hue='group_name',\n",
    "    hue_order=['Control', 'GroupA'],\n",
    "    bins=np.arange(0.0, 1.0, 0.1),\n",
    ").set_title('Total');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_total[df_metrics_total['group_name'] == 'Control']['acceptance_rate'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_total[df_metrics_total['group_name'] == 'GroupA']['acceptance_rate'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearize_data(data, control, numerator, denominator):\n",
    "    df = data.copy()\n",
    "    conversions = df[df[\"group_name\"] == control][numerator].sum()\n",
    "    visitors = df[df[\"group_name\"] == control][denominator].sum()\n",
    "    k = conversions / visitors\n",
    "    df[f\"linearized_{denominator}\"] = k * df[denominator]\n",
    "    df[f\"linearized_{numerator}\"] = (\n",
    "        df[numerator] - df[f\"linearized_{denominator}\"]\n",
    "        ).astype(float)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_total = calculate_absolute_metrics(\n",
    "    df_recprice_prepared,\n",
    "    df_orders_with_recprice,\n",
    "    group_cols=['order_uuid', 'group_name'],\n",
    ")\n",
    "\n",
    "df_metrics_total = df_metrics_total[df_metrics_total['bids_count'] > 0]\n",
    "\n",
    "lin_metrics = linearize_data(df_metrics_total, 'Control', 'accepted_orders_count', 'bids_count')\n",
    "\n",
    "lin_metrics['acceptance_rate'] = lin_metrics['linearized_accepted_orders_count'] / lin_metrics['linearized_bids_count']\n",
    "\n",
    "sns.histplot(\n",
    "    lin_metrics,\n",
    "    x='acceptance_rate',\n",
    "    hue='group_name',\n",
    "    hue_order=['Control', 'GroupA'],\n",
    "    bins=np.arange(0.0, 12.0, 0.1),\n",
    ").set_title('Total');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Группируем данные по acceptance_rate и group_name, считаем количество\n",
    "plot_data = lin_metrics.groupby(['acceptance_rate', 'group_name']).size().reset_index(name='count')\n",
    "\n",
    "# Создаем график\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Строим линии для каждой группы\n",
    "for group in ['Control', 'GroupA']:\n",
    "    group_data = plot_data[plot_data['group_name'] == group]\n",
    "    plt.plot(group_data['acceptance_rate'], group_data['count'], \n",
    "             marker='o', linestyle='-', label=group)\n",
    "\n",
    "plt.xlabel('Acceptance Rate')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Acceptance Rate by Group')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
